# 思路

我们回顾一下广告样本系统主要面临的问题与挑战。

- 数据量大，存储占空间比较大, 需要高性能的读取。
- 一条样本里会包含一个 `user`，多个 `item`。如果 `user` 数据展开会很浪费。
- 同一个目录或者表只能保存部分数据，或者一个场景的数据，经常会需要对数据进行 `join` 操作，`base` 数据通常很大，`join` 通常需要全局 `shuffle` 数据，导致 `join` 很慢。
- 训练时会同时按行或按列进行过滤, 通常是在训练框架的 `IO` 模块进行。因此从 `hdfs` 或者 `kafka` 读取数据时需要读全部数据，到训练的 `worker` 上再进行过滤，因此比较浪费带宽。如果过滤后的数据比例很小则这种浪费更严重。
- 训练时会将数据组织成 `batch` 格式在进行训练。
- 训练通常分为离线训练和实时训练。通常离线采用 `hdfs` 存储，实时采用 `kafka`。存储、特征提取、训练等相关逻辑都需要实现两套。

## 业界现有系统

目前了解到的业界的做法大多是基于现有的大数据架构来进行开发。

### 数据格式

#### `protobuf` 序列化

官网：[protobuf](https://protobuf.dev/)

`protobuf`是一种二进制序列化方式，适用于有多种层级关系的数据的添加、修改等操作。

原始数据或者提取的特征采用 `protobuf` 序列化。从样本服务产生发送到 `kafka`，之后进行其他处理。

##### 优点

`protobuf` 比较灵活，使用方便，对于有多种层级关系的数据的添加、修改等操作尤其方便。

##### 缺点

读取时需要先整体反序列化，对于模型训练样本这样大量的数据, 反序列化速度比较慢。

#### `flatbuffer` 序列化

官网：[flatbuffer](https://google.github.io/flatbuffers/)

`flatbuffer` 是另一种序列化方式，适用于只读数据，反序列化不需要时间。

##### 优点

反序列化比较快，不需要时间。读取性能比较好，因为直接使用的是指针。

##### 缺点

构造数据比较麻烦，必须从最底层的数据结构开始构造。因此 在使用上不如 `protobuf` 灵活。同时因为 `flatbuffer` 
读取时是直接读取的指针，因此保存时候就需要按数据进行保存，因此存储空间上会比 `protobuf` 大。

#### `arrow` 列存

官网：[arrow](https://arrow.apache.org/)

`arrow` 是一种在大数据领域应用非常广泛的基于列存的格式，对于模型训练需要读取不同的特征的问题，可以采用 `arrow` 列存的方式来解决。

##### 优点

`arrow` 列存可以按列进行存储，同一列的数据比较有相似性，有利于压缩，因此可以减少存储空间，在读取的时候可以指定需要的列来读取部分数据，
因此可以减少带宽。

##### 缺点

`arrow` 列存需要 `parquet` 格式来存储，而 `parquet` 格式不支持 `append` 操作，因此需要定期进行 `compact` 操作，将数据合并成
一个大的 `parquet` 文件。

同时因为模型训练的样本是按行组织，再组装成 `batch` 进行训练，因此 `arrow` 列存需要进行几次转换操作才能进行训练。

- 第一次是将 `parquet` 文件反序列化成 `arrow` 格式。
- 第二次是将 `arrow` 格式从列转成行的格式。
- 第三次是将行格式转成 `batch` 格式。

这些转换操作会消耗 `cpu` 资源, 同时不可避免的会有一些数据拷贝的操作。

### 压缩

对于数据量大的问题，可以采用压缩的方式来解决。如 `gzip`, `zstd` 等压缩算法。

#### 优点

压缩的数据占用存储空间小。

#### 缺点

代价是解压的时候会需要更多的 `cpu` 资源。 压缩比越大，解压的速度就越慢。


### 存储系统

#### 离线

常见的做法是采用 `hdfs` 来存储。 比较简单的方式是采用 `protobuf` 或者 `flatbuffer` 格式序列化，然后进行 `base64` 编码
存储在 `hdfs` 上。存储时 `hdfs` 会进行 `snappy` 或者 `gzip` 压缩。

##### 优点

`hdfs` 存储比较简单，容易实现。能够存储大量的数据。

##### 缺点

适合离线训练，不适合实时训练。

#### 实时

常见的做法是采用 `kafka` 来传输数据，数据比较实时。

##### 优点

数据比较实时，训练能够获取最实时的数据。

##### 缺点

只能读取最新的数据，不能读取历史数据。


#### 数据湖

`hudi` 官网：[hudi](https://hudi.apache.org/)

`hudi` 是一种数据湖的存储系统，可以存储多种数据格式，如 `parquet`, `orc`, `avro` 等。

##### 优点

可以支持近实时的写入，以替代 `kafka` 的实时数据传输。因此可以用一套系统替代离线与实时两套系统。

##### 缺点

暂时了解还不多。待补充。

### 计算逻辑

执行数据处理以及特征提取等计算逻辑。

这一部分也是有多种不同的方案，`spark`, `flink`, `hive transform` 等。

这一环节的目标可以如下描述: 如何尽可能高效的执行一段代码，但同时又保证易用性、扩展性、通用性等关键指标。

这一问题实际是一个很宏大的问题，技术上已有完美的解决思路，稍后再做详细讨论。

### `join` 数据


同一个目录或者 `hive` 表只能保存部分数据，不可能保存全部数据。而对数据进行 `join` 又是一个常见的操作，比如将新数据和 `base` 数据进行 `join`。

#### `inner join` 或 `map join`

用 `hive` `inner join` 或 `map join` 的方式来 `join` 数据。

##### 优点

`hive` 的 `join` 操作比较简单，容易实现。

##### 缺点

`hive` 的 `join` 需要对数据进行 `shuffle`，因此比较消耗资源，也比较慢。

`hive` `map join` 能支持的数据量比较小。如果数据量大则会失败。

#### `bucket join`

`bucket join` 是指先将数据保存成分桶表的方式，然后在读取的时候同时读两张表，在内存中进行 `join` 操作。

##### 优点

`bucket join` 可以减少 `join` 操作的资源消耗，提高 `join` 操作的效率。

##### 缺点

- `bucket join` 需要对数据提前按照确定的 `key` 进行分桶报错，且桶的个数也有限制。
- `join` 的两个表的 `key` 必须保持一致，且桶的个数也必须一样，因此不是很灵活。
- 一般 `join` 的 `key` 是 `user_id` 或者 `item_id`, 按照 `key` 进行分桶存储后丢失了原数据中的时间顺序。即数据不是按时间顺序来
进行存储，在训练时候获取的样本也就不是按时间顺序。对于一些和时间关系比较大的特征或者 `label` 可能会有影响，比如小范围穿越等，具体影响
还需要进一步分析。

## 主要挑战以及解决思路

### 主要挑战

广告模型样本有如下一些独有的特点:
- 数据以 `int` 类型为主。
- 训练时数据会组织成 `batch` 格式。
- 每条样本里都必须有时间戳、`user_id`、`item_id`，以及 `request_id`, 可以唯一确定一条样本。

目前的系统都是基于大数据方面的通用架构来设计，这些特点在目前的通用格式中都没有被很好的利用。有些问题被忽略了，有些问题则采用了其他折中
的方案。即目前的解决思路都是想办法用通用的架构来解决广告模型样本的问题，而这些架构中有很多设计的出发点是基于更通用的场景，如各种事务
的支持，各种复杂格式的支持等。这些问题在广告模型中并不存在，但是也会带来一定的开销。

### 解决思路

我们如果反过来思考，围绕这些特点专门为广告模型样本设计一套系统，是否就可以简化问题，实现一套高效的系统?

样本中大部分数据是 `int` 类型，并且相同数据源或者相同特征的数据在样本中会重复出现，对于这种类型的数据，存在一种比通用压缩更高效的压缩方式，
那就是 `simd` 压缩。这种方式可以实现很高的压缩比，同时处理速度也非常快。

对于 `batch` 格式的问题，我们可以直接将数据存成 `batch` 的格式，这样在读取的时候就不需要进行转换操作，减少了转换操作带来的性能损耗。
序列化和反序列化的时候则采用 `simd` 的方式来处理。这一格式已在另一个项目中实现，命名为 [gridbuffer](https://github.com/liuzhishan/gridbuffer)。

对于样本按行按列进行过滤的问题，`batch` 格式可以很方便的按行和按列进行 `mask` 操作, 同时不会存在 `malloc`、拷贝数据等性能开销。

`simd` 加 `batch` 的方式相比 `protobuf`、`flatbuffer` 等通用格式在压缩与读写性能上都有明显的优势。

数据按照表进行存储，每个表所存储的列是固定的。

对于 `join` 的问题，`bucket join` 的核心是提供了分桶的有序的 `key`。但是如前面所提到的，以 `user_id` 或者 `item_id` 作为 `key` 
进行分桶存储后丢失了原数据中的时间顺序。是否有更好的信息可以作为有序的 `key` 呢？我们发现每条样本中有一个关键的信息是天然有序的，那就是
时间戳，一般可以精确到毫秒。如果我们以时间戳来进行分桶，可以很好的解决分桶以及 `join` 的问题。

并且我们发现如果将按时间分区分的更细一点，比如 `30 s` 甚至 `5 s` 一个分区，那么就可以提供替代 `kafka` 的近实时数据传输。分区越细则越实时。

这样既解决了 `join` 数据的问题，又解决了离线实时两套系统冗余的问题。

至此，`droplet` 的思路已经基本成型。即以 `simd` 压缩、`batch` 格式、时间分区为基本点，来构建一套新的专为广告模型样本设计的存储与读写系统。